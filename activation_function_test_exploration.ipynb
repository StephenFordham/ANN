{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('species', axis=1)\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.5, 3. , 5.8, 2.2],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [5.9, 3. , 5.1, 1.8],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [5.7, 3. , 4.2, 1.2]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4, activation='relu', input_shape=[4,]))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 1.0798 - accuracy: 0.3167 - val_loss: 1.0678 - val_accuracy: 0.3667\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0758 - accuracy: 0.3167 - val_loss: 1.0658 - val_accuracy: 0.3667\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0720 - accuracy: 0.3167 - val_loss: 1.0640 - val_accuracy: 0.3667\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0688 - accuracy: 0.3167 - val_loss: 1.0621 - val_accuracy: 0.3667\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0648 - accuracy: 0.3167 - val_loss: 1.0603 - val_accuracy: 0.3667\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0616 - accuracy: 0.3250 - val_loss: 1.0584 - val_accuracy: 0.4000\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0578 - accuracy: 0.3333 - val_loss: 1.0565 - val_accuracy: 0.4333\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 1.0542 - accuracy: 0.3250 - val_loss: 1.0547 - val_accuracy: 0.4333\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0507 - accuracy: 0.3250 - val_loss: 1.0528 - val_accuracy: 0.4000\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0477 - accuracy: 0.3583 - val_loss: 1.0508 - val_accuracy: 0.3667\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0439 - accuracy: 0.3500 - val_loss: 1.0486 - val_accuracy: 0.4000\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0404 - accuracy: 0.3667 - val_loss: 1.0463 - val_accuracy: 0.4000\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0369 - accuracy: 0.4000 - val_loss: 1.0440 - val_accuracy: 0.3667\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0337 - accuracy: 0.4083 - val_loss: 1.0417 - val_accuracy: 0.3667\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0299 - accuracy: 0.5000 - val_loss: 1.0392 - val_accuracy: 0.5000\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0265 - accuracy: 0.5750 - val_loss: 1.0365 - val_accuracy: 0.5333\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.0231 - accuracy: 0.6583 - val_loss: 1.0339 - val_accuracy: 0.5667\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0191 - accuracy: 0.7083 - val_loss: 1.0311 - val_accuracy: 0.6333\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0155 - accuracy: 0.7250 - val_loss: 1.0281 - val_accuracy: 0.6333\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0117 - accuracy: 0.7417 - val_loss: 1.0249 - val_accuracy: 0.6333\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0078 - accuracy: 0.7417 - val_loss: 1.0217 - val_accuracy: 0.6333\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0042 - accuracy: 0.7583 - val_loss: 1.0185 - val_accuracy: 0.6333\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0001 - accuracy: 0.7583 - val_loss: 1.0153 - val_accuracy: 0.6333\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9961 - accuracy: 0.7333 - val_loss: 1.0118 - val_accuracy: 0.6667\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9921 - accuracy: 0.7250 - val_loss: 1.0083 - val_accuracy: 0.6667\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9880 - accuracy: 0.7250 - val_loss: 1.0047 - val_accuracy: 0.6667\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9837 - accuracy: 0.7250 - val_loss: 1.0010 - val_accuracy: 0.6333\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9795 - accuracy: 0.7250 - val_loss: 0.9972 - val_accuracy: 0.6333\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9753 - accuracy: 0.7250 - val_loss: 0.9935 - val_accuracy: 0.6333\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9708 - accuracy: 0.7250 - val_loss: 0.9897 - val_accuracy: 0.6333\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9666 - accuracy: 0.7167 - val_loss: 0.9861 - val_accuracy: 0.6667\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9621 - accuracy: 0.7083 - val_loss: 0.9824 - val_accuracy: 0.6333\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9576 - accuracy: 0.7000 - val_loss: 0.9784 - val_accuracy: 0.6000\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9529 - accuracy: 0.7000 - val_loss: 0.9742 - val_accuracy: 0.6000\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9485 - accuracy: 0.7000 - val_loss: 0.9704 - val_accuracy: 0.6000\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9441 - accuracy: 0.6917 - val_loss: 0.9664 - val_accuracy: 0.6000\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9395 - accuracy: 0.6917 - val_loss: 0.9623 - val_accuracy: 0.6000\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9349 - accuracy: 0.6917 - val_loss: 0.9584 - val_accuracy: 0.6000\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9303 - accuracy: 0.6917 - val_loss: 0.9545 - val_accuracy: 0.6000\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9260 - accuracy: 0.6917 - val_loss: 0.9504 - val_accuracy: 0.6000\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.9212 - accuracy: 0.6833 - val_loss: 0.9465 - val_accuracy: 0.6000\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9165 - accuracy: 0.6833 - val_loss: 0.9426 - val_accuracy: 0.6000\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9120 - accuracy: 0.6833 - val_loss: 0.9387 - val_accuracy: 0.6000\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.9074 - accuracy: 0.6833 - val_loss: 0.9349 - val_accuracy: 0.6000\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.9028 - accuracy: 0.6833 - val_loss: 0.9304 - val_accuracy: 0.6000\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8983 - accuracy: 0.6833 - val_loss: 0.9263 - val_accuracy: 0.6000\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8933 - accuracy: 0.6833 - val_loss: 0.9221 - val_accuracy: 0.6000\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8886 - accuracy: 0.6833 - val_loss: 0.9179 - val_accuracy: 0.6000\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8839 - accuracy: 0.6833 - val_loss: 0.9138 - val_accuracy: 0.6000\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.8793 - accuracy: 0.6833 - val_loss: 0.9096 - val_accuracy: 0.6000\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8744 - accuracy: 0.6833 - val_loss: 0.9052 - val_accuracy: 0.6000\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8696 - accuracy: 0.6833 - val_loss: 0.9008 - val_accuracy: 0.6000\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8648 - accuracy: 0.6833 - val_loss: 0.8963 - val_accuracy: 0.6000\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8601 - accuracy: 0.6833 - val_loss: 0.8917 - val_accuracy: 0.6000\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8552 - accuracy: 0.6833 - val_loss: 0.8876 - val_accuracy: 0.6000\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8503 - accuracy: 0.6833 - val_loss: 0.8831 - val_accuracy: 0.6000\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8454 - accuracy: 0.6833 - val_loss: 0.8789 - val_accuracy: 0.6000\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.8405 - accuracy: 0.6833 - val_loss: 0.8745 - val_accuracy: 0.6000\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8358 - accuracy: 0.6833 - val_loss: 0.8701 - val_accuracy: 0.6000\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8308 - accuracy: 0.6833 - val_loss: 0.8657 - val_accuracy: 0.6000\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8261 - accuracy: 0.6833 - val_loss: 0.8614 - val_accuracy: 0.6000\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8210 - accuracy: 0.6833 - val_loss: 0.8569 - val_accuracy: 0.6000\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8161 - accuracy: 0.6917 - val_loss: 0.8523 - val_accuracy: 0.6000\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.8114 - accuracy: 0.6917 - val_loss: 0.8475 - val_accuracy: 0.6000\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8063 - accuracy: 0.6917 - val_loss: 0.8433 - val_accuracy: 0.6000\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8016 - accuracy: 0.6917 - val_loss: 0.8387 - val_accuracy: 0.6000\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7966 - accuracy: 0.6917 - val_loss: 0.8345 - val_accuracy: 0.6000\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7919 - accuracy: 0.6917 - val_loss: 0.8301 - val_accuracy: 0.6000\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7871 - accuracy: 0.6917 - val_loss: 0.8262 - val_accuracy: 0.6000\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7825 - accuracy: 0.6917 - val_loss: 0.8221 - val_accuracy: 0.6000\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7775 - accuracy: 0.6917 - val_loss: 0.8176 - val_accuracy: 0.6000\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7729 - accuracy: 0.6917 - val_loss: 0.8131 - val_accuracy: 0.6000\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7680 - accuracy: 0.6917 - val_loss: 0.8091 - val_accuracy: 0.6000\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7633 - accuracy: 0.6917 - val_loss: 0.8047 - val_accuracy: 0.6000\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7587 - accuracy: 0.6917 - val_loss: 0.8004 - val_accuracy: 0.6000\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7540 - accuracy: 0.6917 - val_loss: 0.7962 - val_accuracy: 0.6000\n",
      "Epoch 77/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7494 - accuracy: 0.6917 - val_loss: 0.7918 - val_accuracy: 0.6000\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7448 - accuracy: 0.6917 - val_loss: 0.7877 - val_accuracy: 0.6000\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.7403 - accuracy: 0.6917 - val_loss: 0.7835 - val_accuracy: 0.6000\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7356 - accuracy: 0.6917 - val_loss: 0.7792 - val_accuracy: 0.6333\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7311 - accuracy: 0.6917 - val_loss: 0.7750 - val_accuracy: 0.6333\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7266 - accuracy: 0.6917 - val_loss: 0.7707 - val_accuracy: 0.6333\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7222 - accuracy: 0.6917 - val_loss: 0.7666 - val_accuracy: 0.6333\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7177 - accuracy: 0.6917 - val_loss: 0.7625 - val_accuracy: 0.6333\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7133 - accuracy: 0.6917 - val_loss: 0.7583 - val_accuracy: 0.6333\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.7090 - accuracy: 0.6917 - val_loss: 0.7541 - val_accuracy: 0.6333\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7046 - accuracy: 0.6917 - val_loss: 0.7502 - val_accuracy: 0.6333\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.7003 - accuracy: 0.6917 - val_loss: 0.7463 - val_accuracy: 0.6333\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6962 - accuracy: 0.6917 - val_loss: 0.7424 - val_accuracy: 0.6333\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6919 - accuracy: 0.6917 - val_loss: 0.7380 - val_accuracy: 0.6333\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6877 - accuracy: 0.6917 - val_loss: 0.7340 - val_accuracy: 0.6333\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6835 - accuracy: 0.6917 - val_loss: 0.7298 - val_accuracy: 0.6333\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6795 - accuracy: 0.6917 - val_loss: 0.7260 - val_accuracy: 0.6333\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6754 - accuracy: 0.6917 - val_loss: 0.7223 - val_accuracy: 0.6333\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6713 - accuracy: 0.6917 - val_loss: 0.7183 - val_accuracy: 0.6333\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6673 - accuracy: 0.6917 - val_loss: 0.7145 - val_accuracy: 0.6333\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6634 - accuracy: 0.6917 - val_loss: 0.7110 - val_accuracy: 0.6333\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6593 - accuracy: 0.6917 - val_loss: 0.7075 - val_accuracy: 0.6333\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6556 - accuracy: 0.6917 - val_loss: 0.7040 - val_accuracy: 0.6333\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6517 - accuracy: 0.6917 - val_loss: 0.7009 - val_accuracy: 0.6333\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.6480 - accuracy: 0.6917 - val_loss: 0.6975 - val_accuracy: 0.6333\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6442 - accuracy: 0.6917 - val_loss: 0.6941 - val_accuracy: 0.6333\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6405 - accuracy: 0.6917 - val_loss: 0.6907 - val_accuracy: 0.6333\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6369 - accuracy: 0.6917 - val_loss: 0.6870 - val_accuracy: 0.6333\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6333 - accuracy: 0.7000 - val_loss: 0.6836 - val_accuracy: 0.6333\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6297 - accuracy: 0.7000 - val_loss: 0.6800 - val_accuracy: 0.6333\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6262 - accuracy: 0.7000 - val_loss: 0.6762 - val_accuracy: 0.6667\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.6227 - accuracy: 0.7000 - val_loss: 0.6730 - val_accuracy: 0.6667\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6191 - accuracy: 0.7000 - val_loss: 0.6696 - val_accuracy: 0.6667\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6158 - accuracy: 0.7083 - val_loss: 0.6663 - val_accuracy: 0.6667\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6124 - accuracy: 0.7167 - val_loss: 0.6627 - val_accuracy: 0.6667\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6894 - accuracy: 0.71 - 0s 10ms/step - loss: 0.6090 - accuracy: 0.7167 - val_loss: 0.6594 - val_accuracy: 0.6667\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6058 - accuracy: 0.7250 - val_loss: 0.6557 - val_accuracy: 0.6667\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.6025 - accuracy: 0.7333 - val_loss: 0.6524 - val_accuracy: 0.6667\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5993 - accuracy: 0.7333 - val_loss: 0.6495 - val_accuracy: 0.6667\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5960 - accuracy: 0.7333 - val_loss: 0.6462 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5930 - accuracy: 0.7417 - val_loss: 0.6428 - val_accuracy: 0.6667\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5897 - accuracy: 0.7417 - val_loss: 0.6398 - val_accuracy: 0.6667\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5867 - accuracy: 0.7417 - val_loss: 0.6370 - val_accuracy: 0.6667\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5836 - accuracy: 0.7417 - val_loss: 0.6341 - val_accuracy: 0.6667\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5808 - accuracy: 0.7417 - val_loss: 0.6309 - val_accuracy: 0.6667\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5776 - accuracy: 0.7500 - val_loss: 0.6281 - val_accuracy: 0.6667\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5747 - accuracy: 0.7500 - val_loss: 0.6254 - val_accuracy: 0.6667\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5718 - accuracy: 0.7500 - val_loss: 0.6227 - val_accuracy: 0.7000\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5690 - accuracy: 0.7500 - val_loss: 0.6199 - val_accuracy: 0.7000\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5661 - accuracy: 0.7500 - val_loss: 0.6172 - val_accuracy: 0.7000\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5634 - accuracy: 0.7583 - val_loss: 0.6143 - val_accuracy: 0.7000\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5606 - accuracy: 0.7583 - val_loss: 0.6116 - val_accuracy: 0.7000\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5578 - accuracy: 0.7583 - val_loss: 0.6090 - val_accuracy: 0.7000\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5551 - accuracy: 0.7583 - val_loss: 0.6064 - val_accuracy: 0.7333\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5525 - accuracy: 0.7583 - val_loss: 0.6041 - val_accuracy: 0.7000\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5499 - accuracy: 0.7583 - val_loss: 0.6017 - val_accuracy: 0.7000\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5474 - accuracy: 0.7583 - val_loss: 0.5988 - val_accuracy: 0.7333\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5447 - accuracy: 0.7667 - val_loss: 0.5959 - val_accuracy: 0.7667\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5422 - accuracy: 0.7750 - val_loss: 0.5931 - val_accuracy: 0.7667\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5397 - accuracy: 0.7833 - val_loss: 0.5905 - val_accuracy: 0.7667\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5373 - accuracy: 0.8000 - val_loss: 0.5880 - val_accuracy: 0.7667\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5348 - accuracy: 0.8000 - val_loss: 0.5853 - val_accuracy: 0.7667\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5325 - accuracy: 0.8000 - val_loss: 0.5824 - val_accuracy: 0.7667\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5300 - accuracy: 0.8000 - val_loss: 0.5800 - val_accuracy: 0.7667\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5277 - accuracy: 0.8000 - val_loss: 0.5775 - val_accuracy: 0.7667\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5254 - accuracy: 0.8083 - val_loss: 0.5749 - val_accuracy: 0.7667\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5231 - accuracy: 0.8083 - val_loss: 0.5724 - val_accuracy: 0.7667\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5208 - accuracy: 0.8167 - val_loss: 0.5702 - val_accuracy: 0.7667\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.5186 - accuracy: 0.8167 - val_loss: 0.5680 - val_accuracy: 0.7667\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.5163 - accuracy: 0.8167 - val_loss: 0.5656 - val_accuracy: 0.7667\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5142 - accuracy: 0.8250 - val_loss: 0.5633 - val_accuracy: 0.8000\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5270 - accuracy: 0.81 - 0s 10ms/step - loss: 0.5119 - accuracy: 0.8333 - val_loss: 0.5611 - val_accuracy: 0.8000\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5098 - accuracy: 0.8333 - val_loss: 0.5589 - val_accuracy: 0.8000\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4731 - accuracy: 0.93 - 0s 9ms/step - loss: 0.5077 - accuracy: 0.8333 - val_loss: 0.5568 - val_accuracy: 0.8000\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5057 - accuracy: 0.8333 - val_loss: 0.5550 - val_accuracy: 0.8000\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5036 - accuracy: 0.8333 - val_loss: 0.5529 - val_accuracy: 0.8000\n",
      "Epoch 153/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5015 - accuracy: 0.8333 - val_loss: 0.5509 - val_accuracy: 0.8000\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4995 - accuracy: 0.8333 - val_loss: 0.5485 - val_accuracy: 0.8000\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4974 - accuracy: 0.8333 - val_loss: 0.5464 - val_accuracy: 0.8000\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4955 - accuracy: 0.8333 - val_loss: 0.5443 - val_accuracy: 0.8000\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4935 - accuracy: 0.8333 - val_loss: 0.5425 - val_accuracy: 0.8000\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4916 - accuracy: 0.8333 - val_loss: 0.5405 - val_accuracy: 0.8000\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4897 - accuracy: 0.8333 - val_loss: 0.5383 - val_accuracy: 0.8000\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4878 - accuracy: 0.8250 - val_loss: 0.5361 - val_accuracy: 0.8000\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4860 - accuracy: 0.8250 - val_loss: 0.5343 - val_accuracy: 0.8000\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4842 - accuracy: 0.8250 - val_loss: 0.5320 - val_accuracy: 0.8000\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4822 - accuracy: 0.8250 - val_loss: 0.5300 - val_accuracy: 0.8000\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4804 - accuracy: 0.8250 - val_loss: 0.5281 - val_accuracy: 0.8000\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4787 - accuracy: 0.8250 - val_loss: 0.5261 - val_accuracy: 0.8000\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4768 - accuracy: 0.8250 - val_loss: 0.5244 - val_accuracy: 0.8000\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4751 - accuracy: 0.8250 - val_loss: 0.5226 - val_accuracy: 0.8000\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4734 - accuracy: 0.8250 - val_loss: 0.5206 - val_accuracy: 0.8000\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4717 - accuracy: 0.8250 - val_loss: 0.5187 - val_accuracy: 0.8000\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4698 - accuracy: 0.8250 - val_loss: 0.5171 - val_accuracy: 0.8000\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4682 - accuracy: 0.8250 - val_loss: 0.5156 - val_accuracy: 0.8000\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4666 - accuracy: 0.8250 - val_loss: 0.5138 - val_accuracy: 0.8000\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.8250 - val_loss: 0.5121 - val_accuracy: 0.8000\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4633 - accuracy: 0.8250 - val_loss: 0.5106 - val_accuracy: 0.8000\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4616 - accuracy: 0.8250 - val_loss: 0.5086 - val_accuracy: 0.8000\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3664 - accuracy: 0.90 - 0s 7ms/step - loss: 0.4600 - accuracy: 0.8250 - val_loss: 0.5067 - val_accuracy: 0.8333\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4584 - accuracy: 0.8333 - val_loss: 0.5048 - val_accuracy: 0.8333\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4568 - accuracy: 0.8417 - val_loss: 0.5029 - val_accuracy: 0.8333\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.8417 - val_loss: 0.5010 - val_accuracy: 0.8333\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4537 - accuracy: 0.8417 - val_loss: 0.4991 - val_accuracy: 0.8333\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4521 - accuracy: 0.8500 - val_loss: 0.4974 - val_accuracy: 0.8667\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4505 - accuracy: 0.8500 - val_loss: 0.4959 - val_accuracy: 0.8667\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4491 - accuracy: 0.8500 - val_loss: 0.4939 - val_accuracy: 0.8667\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.93 - 0s 7ms/step - loss: 0.4475 - accuracy: 0.8583 - val_loss: 0.4924 - val_accuracy: 0.8667\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4460 - accuracy: 0.8583 - val_loss: 0.4909 - val_accuracy: 0.8667\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4447 - accuracy: 0.8583 - val_loss: 0.4897 - val_accuracy: 0.8667\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4923 - accuracy: 0.78 - 0s 7ms/step - loss: 0.4431 - accuracy: 0.8583 - val_loss: 0.4880 - val_accuracy: 0.8667\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4416 - accuracy: 0.8583 - val_loss: 0.4866 - val_accuracy: 0.8667\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.8583 - val_loss: 0.4849 - val_accuracy: 0.8667\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.8667 - val_loss: 0.4831 - val_accuracy: 0.8667\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.8750 - val_loss: 0.4813 - val_accuracy: 0.8667\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4359 - accuracy: 0.8750 - val_loss: 0.4798 - val_accuracy: 0.8667\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4345 - accuracy: 0.8750 - val_loss: 0.4785 - val_accuracy: 0.8667\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4330 - accuracy: 0.8750 - val_loss: 0.4772 - val_accuracy: 0.8667\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.8750 - val_loss: 0.4763 - val_accuracy: 0.8667\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4304 - accuracy: 0.8750 - val_loss: 0.4748 - val_accuracy: 0.8667\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.8750 - val_loss: 0.4731 - val_accuracy: 0.8667\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.8750 - val_loss: 0.4718 - val_accuracy: 0.8667\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4263 - accuracy: 0.8750 - val_loss: 0.4702 - val_accuracy: 0.8667\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4249 - accuracy: 0.8750 - val_loss: 0.4686 - val_accuracy: 0.8667\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4236 - accuracy: 0.8750 - val_loss: 0.4670 - val_accuracy: 0.8667\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 84ms/step - loss: 0.4223 - accuracy: 0.8750 - val_loss: 0.4654 - val_accuracy: 0.8667\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4211 - accuracy: 0.8750 - val_loss: 0.4638 - val_accuracy: 0.8667\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4198 - accuracy: 0.8750 - val_loss: 0.4625 - val_accuracy: 0.8667\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8750 - val_loss: 0.4607 - val_accuracy: 0.8667\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4172 - accuracy: 0.8750 - val_loss: 0.4589 - val_accuracy: 0.8667\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4159 - accuracy: 0.8750 - val_loss: 0.4573 - val_accuracy: 0.8667\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4146 - accuracy: 0.8833 - val_loss: 0.4560 - val_accuracy: 0.8667\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4133 - accuracy: 0.8833 - val_loss: 0.4547 - val_accuracy: 0.8667\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4121 - accuracy: 0.8833 - val_loss: 0.4533 - val_accuracy: 0.8667\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4109 - accuracy: 0.8833 - val_loss: 0.4523 - val_accuracy: 0.8667\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4096 - accuracy: 0.8833 - val_loss: 0.4511 - val_accuracy: 0.8667\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4084 - accuracy: 0.8833 - val_loss: 0.4500 - val_accuracy: 0.8667\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4132 - accuracy: 0.87 - 0s 7ms/step - loss: 0.4072 - accuracy: 0.8833 - val_loss: 0.4488 - val_accuracy: 0.8667\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4060 - accuracy: 0.8833 - val_loss: 0.4476 - val_accuracy: 0.8667\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4048 - accuracy: 0.8833 - val_loss: 0.4462 - val_accuracy: 0.8667\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4036 - accuracy: 0.8833 - val_loss: 0.4450 - val_accuracy: 0.9000\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.4024 - accuracy: 0.8833 - val_loss: 0.4435 - val_accuracy: 0.9000\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4013 - accuracy: 0.8833 - val_loss: 0.4421 - val_accuracy: 0.9000\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4001 - accuracy: 0.8833 - val_loss: 0.4407 - val_accuracy: 0.9000\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3989 - accuracy: 0.8833 - val_loss: 0.4393 - val_accuracy: 0.9000\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3977 - accuracy: 0.8833 - val_loss: 0.4378 - val_accuracy: 0.9000\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3966 - accuracy: 0.8833 - val_loss: 0.4363 - val_accuracy: 0.9000\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3955 - accuracy: 0.8917 - val_loss: 0.4350 - val_accuracy: 0.8667\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3943 - accuracy: 0.8917 - val_loss: 0.4338 - val_accuracy: 0.9000\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8917 - val_loss: 0.4328 - val_accuracy: 0.9000\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.8833 - val_loss: 0.4318 - val_accuracy: 0.9000\n",
      "Epoch 228/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3909 - accuracy: 0.8833 - val_loss: 0.4306 - val_accuracy: 0.9000\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3900 - accuracy: 0.8917 - val_loss: 0.4290 - val_accuracy: 0.8667\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3888 - accuracy: 0.9000 - val_loss: 0.4277 - val_accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3878 - accuracy: 0.9000 - val_loss: 0.4269 - val_accuracy: 0.8667\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3866 - accuracy: 0.9000 - val_loss: 0.4257 - val_accuracy: 0.8667\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3263 - accuracy: 1.00 - 0s 7ms/step - loss: 0.3855 - accuracy: 0.9000 - val_loss: 0.4245 - val_accuracy: 0.8667\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4176 - accuracy: 0.84 - 0s 7ms/step - loss: 0.3846 - accuracy: 0.9000 - val_loss: 0.4228 - val_accuracy: 0.8667\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3833 - accuracy: 0.9000 - val_loss: 0.4216 - val_accuracy: 0.8667\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3824 - accuracy: 0.9000 - val_loss: 0.4208 - val_accuracy: 0.8667\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3812 - accuracy: 0.9000 - val_loss: 0.4196 - val_accuracy: 0.8667\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4063 - accuracy: 0.84 - 0s 7ms/step - loss: 0.3801 - accuracy: 0.9000 - val_loss: 0.4184 - val_accuracy: 0.8667\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3792 - accuracy: 0.9000 - val_loss: 0.4176 - val_accuracy: 0.8667\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.9000 - val_loss: 0.4162 - val_accuracy: 0.8667\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3770 - accuracy: 0.9083 - val_loss: 0.4151 - val_accuracy: 0.8667\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.96 - 0s 8ms/step - loss: 0.3760 - accuracy: 0.9083 - val_loss: 0.4140 - val_accuracy: 0.8667\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3750 - accuracy: 0.9083 - val_loss: 0.4131 - val_accuracy: 0.8667\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3739 - accuracy: 0.9083 - val_loss: 0.4118 - val_accuracy: 0.8667\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3729 - accuracy: 0.9083 - val_loss: 0.4106 - val_accuracy: 0.8667\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3719 - accuracy: 0.9083 - val_loss: 0.4095 - val_accuracy: 0.8667\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3709 - accuracy: 0.9083 - val_loss: 0.4083 - val_accuracy: 0.8667\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3245 - accuracy: 0.96 - 0s 8ms/step - loss: 0.3699 - accuracy: 0.9083 - val_loss: 0.4073 - val_accuracy: 0.8667\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3689 - accuracy: 0.9083 - val_loss: 0.4062 - val_accuracy: 0.8667\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3679 - accuracy: 0.9083 - val_loss: 0.4050 - val_accuracy: 0.8667\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3670 - accuracy: 0.9083 - val_loss: 0.4040 - val_accuracy: 0.8667\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3659 - accuracy: 0.9083 - val_loss: 0.4029 - val_accuracy: 0.8667\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3649 - accuracy: 0.9083 - val_loss: 0.4019 - val_accuracy: 0.8667\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3640 - accuracy: 0.9083 - val_loss: 0.4008 - val_accuracy: 0.8667\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3630 - accuracy: 0.9083 - val_loss: 0.3997 - val_accuracy: 0.8667\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3621 - accuracy: 0.9083 - val_loss: 0.3986 - val_accuracy: 0.8667\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3611 - accuracy: 0.9083 - val_loss: 0.3977 - val_accuracy: 0.8667\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3604 - accuracy: 0.9083 - val_loss: 0.3972 - val_accuracy: 0.8667\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3387 - accuracy: 0.90 - 0s 8ms/step - loss: 0.3593 - accuracy: 0.9083 - val_loss: 0.3963 - val_accuracy: 0.8667\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3583 - accuracy: 0.9083 - val_loss: 0.3949 - val_accuracy: 0.8667\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3573 - accuracy: 0.9083 - val_loss: 0.3939 - val_accuracy: 0.8667\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3564 - accuracy: 0.9083 - val_loss: 0.3927 - val_accuracy: 0.8667\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3554 - accuracy: 0.9083 - val_loss: 0.3913 - val_accuracy: 0.8667\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3545 - accuracy: 0.9083 - val_loss: 0.3902 - val_accuracy: 0.8667\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3537 - accuracy: 0.9083 - val_loss: 0.3888 - val_accuracy: 0.8667\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3527 - accuracy: 0.9083 - val_loss: 0.3880 - val_accuracy: 0.8667\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3518 - accuracy: 0.9083 - val_loss: 0.3867 - val_accuracy: 0.8667\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3509 - accuracy: 0.9167 - val_loss: 0.3856 - val_accuracy: 0.8667\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3500 - accuracy: 0.9250 - val_loss: 0.3846 - val_accuracy: 0.8667\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3493 - accuracy: 0.9250 - val_loss: 0.3834 - val_accuracy: 0.9000\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.9250 - val_loss: 0.3828 - val_accuracy: 0.8667\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3473 - accuracy: 0.9250 - val_loss: 0.3818 - val_accuracy: 0.9000\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3464 - accuracy: 0.9250 - val_loss: 0.3812 - val_accuracy: 0.8667\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3455 - accuracy: 0.9167 - val_loss: 0.3803 - val_accuracy: 0.8667\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3446 - accuracy: 0.9167 - val_loss: 0.3796 - val_accuracy: 0.8667\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3437 - accuracy: 0.9167 - val_loss: 0.3788 - val_accuracy: 0.8667\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3428 - accuracy: 0.9167 - val_loss: 0.3780 - val_accuracy: 0.8667\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3420 - accuracy: 0.9167 - val_loss: 0.3771 - val_accuracy: 0.8667\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3411 - accuracy: 0.9167 - val_loss: 0.3760 - val_accuracy: 0.8667\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3402 - accuracy: 0.9167 - val_loss: 0.3749 - val_accuracy: 0.9000\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2619 - accuracy: 0.93 - 0s 7ms/step - loss: 0.3394 - accuracy: 0.9167 - val_loss: 0.3737 - val_accuracy: 0.9000\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3385 - accuracy: 0.9250 - val_loss: 0.3727 - val_accuracy: 0.9000\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3377 - accuracy: 0.9250 - val_loss: 0.3719 - val_accuracy: 0.9000\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3368 - accuracy: 0.9250 - val_loss: 0.3710 - val_accuracy: 0.9000\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3360 - accuracy: 0.9167 - val_loss: 0.3705 - val_accuracy: 0.9000\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3351 - accuracy: 0.9167 - val_loss: 0.3695 - val_accuracy: 0.9000\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3343 - accuracy: 0.9167 - val_loss: 0.3684 - val_accuracy: 0.9000\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3335 - accuracy: 0.9167 - val_loss: 0.3678 - val_accuracy: 0.9000\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3327 - accuracy: 0.9167 - val_loss: 0.3667 - val_accuracy: 0.9000\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.90 - 0s 8ms/step - loss: 0.3318 - accuracy: 0.9167 - val_loss: 0.3655 - val_accuracy: 0.9000\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3310 - accuracy: 0.9250 - val_loss: 0.3646 - val_accuracy: 0.9000\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3302 - accuracy: 0.9250 - val_loss: 0.3634 - val_accuracy: 0.9000\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3293 - accuracy: 0.9250 - val_loss: 0.3626 - val_accuracy: 0.9000\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3285 - accuracy: 0.9250 - val_loss: 0.3616 - val_accuracy: 0.9000\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3277 - accuracy: 0.9250 - val_loss: 0.3606 - val_accuracy: 0.9000\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3270 - accuracy: 0.9250 - val_loss: 0.3595 - val_accuracy: 0.9000\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3260 - accuracy: 0.9250 - val_loss: 0.3587 - val_accuracy: 0.9000\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3252 - accuracy: 0.9250 - val_loss: 0.3580 - val_accuracy: 0.9000\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3244 - accuracy: 0.9250 - val_loss: 0.3574 - val_accuracy: 0.9000\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.3236 - accuracy: 0.9250 - val_loss: 0.3567 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22b2cb07208>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[early_stop], epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [loss, accuracy, val_loss, val_accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22b2ef78108>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22b33379bc8>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 2, 2, 2, 1, 2, 0, 2, 0, 0, 2, 2, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 2, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {'sepal_length' : 5.1,\n",
    "                 'sepal_width': 3.5,\n",
    "                 'petal_length' : 1.4,\n",
    "                 'petal_width' : 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('iris_flower_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('iris_flower_model.h5')\n",
    "flower_scaler = joblib.load('iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_prediction(model, scaler, sample_json):\n",
    "    s_len = sample_json['sepal_length']\n",
    "    s_wid = sample_json['sepal_width']\n",
    "    p_len = sample_json['petal_length']\n",
    "    p_wid = sample_json['petal_width']\n",
    "    \n",
    "    flower = [[s_len, s_wid, p_len, p_wid]]\n",
    "    \n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica'])\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return classes[class_ind][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_prediction(flower_model, flower_scaler, flower_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_flower = df.drop('species', axis=1).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    5.1\n",
       "sepal_width     3.5\n",
       "petal_length    1.4\n",
       "petal_width     0.2\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_flower = scaler.transform(sample_flower.values.reshape(-1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(sample_flower)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setosa'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9788792 , 0.01589416, 0.00522665]], dtype=float32)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sample_flower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The sum of the probabilities equals 1\n",
    "\n",
    "## using activation='softmax', in last neuron layer\n",
    "## and loss 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sample_flower)[0].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 80% probability of sample_flower being setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False, False]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sample_flower) > 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
